{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729c4a7a",
   "metadata": {},
   "source": [
    "# 01 — Config + Index + Split + Dataloaders (FIX)\n",
    "\n",
    "Este notebook:\n",
    "- Configura rutas/semilla\n",
    "- Indexa imágenes\n",
    "- Divide **train/val/test** (estratificado)\n",
    "- **Guarda los splits** en `OUT_DIR` (CSV) para reutilizarlos en todos los notebooks\n",
    "- Construye `train_loader`, `val_loader`, `test_loader` con transforms correctos (`train_tfms` y `eval_tfms`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6703583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Config guardada en: C:\\Users\\User\\Downloads\\COVID_HYBRID_experiment2\\config_runtime.json\n"
     ]
    }
   ],
   "source": [
    "# ===== CONFIG (FIX) =====\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Rutas (ajusta a tu máquina)\n",
    "DATA_DIR = r\"C:\\Users\\User\\Downloads\\Dataset_COVID\\Balanceo\"\n",
    "OUT_DIR  = r\"C:\\Users\\User\\Downloads\\COVID_HYBRID_experiment2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Dispositivo\n",
    "USE_GPU = True\n",
    "DEVICE = \"cuda\" if (USE_GPU and torch.cuda.is_available()) else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Hiperparámetros base (mismos que tu notebook)\n",
    "IMG_SIZE    = 224\n",
    "BATCH_SIZE  = 12\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "CLASS_NAMES = [\"No-COVID\",\"COVID\"]\n",
    "\n",
    "# Guardamos una mini-config para que otros notebooks se sincronicen\n",
    "import json\n",
    "with open(os.path.join(OUT_DIR, \"config_runtime.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dict(SEED=SEED, IMG_SIZE=IMG_SIZE, BATCH_SIZE=BATCH_SIZE, NUM_WORKERS=NUM_WORKERS,\n",
    "                   CLASS_NAMES=CLASS_NAMES), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Config guardada en:\", os.path.join(OUT_DIR, \"config_runtime.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cfa6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes: 9564\n",
      "label\n",
      "0    5948\n",
      "1    3616\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===== INDEX + SUBSET (usa tu función original, aquí va un ejemplo genérico) =====\n",
    "import pandas as pd\n",
    "\n",
    "def build_index(root):\n",
    "    rows = []\n",
    "    for cls in sorted(os.listdir(root)):\n",
    "        d = os.path.join(root, cls)\n",
    "        if not os.path.isdir(d): \n",
    "            continue\n",
    "        for f in os.listdir(d):\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if ext in [\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"]:\n",
    "                rows.append((os.path.join(d,f), cls))\n",
    "    df = pd.DataFrame(rows, columns=[\"path\",\"class\"])\n",
    "    return df\n",
    "\n",
    "df = build_index(DATA_DIR)\n",
    "\n",
    "# Mapea clases a labels binarios de forma explícita (ajusta si tu carpeta usa otros nombres)\n",
    "# Asumimos: \"COVID\" -> 1, \"No-COVID\"/\"Normal\" -> 0\n",
    "def to_label(c):\n",
    "    c_up = str(c).strip().upper()\n",
    "    if \"COVID\" in c_up:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df[\"label\"] = df[\"class\"].apply(to_label)\n",
    "\n",
    "print(\"Total imágenes:\", len(df))\n",
    "print(df[\"label\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57316afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (6909): {0: 4297, 1: 2612}\n",
      "val (1220): {0: 759, 1: 461}\n",
      "test (1435): {0: 892, 1: 543}\n",
      "Splits guardados:\n",
      " - C:\\Users\\User\\Downloads\\COVID_HYBRID_experiment2\\train_split.csv\n",
      " - C:\\Users\\User\\Downloads\\COVID_HYBRID_experiment2\\val_split.csv\n",
      " - C:\\Users\\User\\Downloads\\COVID_HYBRID_experiment2\\test_split.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== SPLIT (estratificado) + GUARDAR CSV =====\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.15, stratify=df[\"label\"], random_state=SEED\n",
    ")\n",
    "train_df, val_df  = train_test_split(\n",
    "    train_df, test_size=0.15, stratify=train_df[\"label\"], random_state=SEED\n",
    ")\n",
    "\n",
    "for name, part in [(\"train\",train_df),(\"val\",val_df),(\"test\",test_df)]:\n",
    "    print(f\"{name} ({len(part)}):\", part[\"label\"].value_counts().sort_index().to_dict())\n",
    "\n",
    "# Guardar splits (clave para NO evaluar con todo el dataset por error)\n",
    "train_path = os.path.join(OUT_DIR, \"train_split.csv\")\n",
    "val_path   = os.path.join(OUT_DIR, \"val_split.csv\")\n",
    "test_path  = os.path.join(OUT_DIR, \"test_split.csv\")\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Splits guardados:\")\n",
    "print(\" -\", train_path)\n",
    "print(\" -\", val_path)\n",
    "print(\" -\", test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615feec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity batch: torch.Size([12, 3, 224, 224]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# ===== DATASET + DATALOADERS (FIX: sin '...' y con eval_tfms) =====\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.df.iloc[idx][\"path\"]\n",
    "        y = int(self.df.iloc[idx][\"label\"])\n",
    "        img = Image.open(p).convert(\"L\").convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "# Train transforms: leves (no cambiamos tu pipeline, solo arreglamos la celda rota)\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(7),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "\n",
    "# Eval/Test transforms: deterministas\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "\n",
    "train_ds = XRayDataset(train_df, transform=train_tfms)\n",
    "val_ds   = XRayDataset(val_df,   transform=eval_tfms)\n",
    "test_ds  = XRayDataset(test_df,  transform=eval_tfms)\n",
    "\n",
    "loader_kwargs = dict(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=(DEVICE==\"cuda\"))\n",
    "train_loader = DataLoader(train_ds, shuffle=True,  **loader_kwargs)\n",
    "val_loader   = DataLoader(val_ds,   shuffle=False, **loader_kwargs)\n",
    "test_loader  = DataLoader(test_ds,  shuffle=False, **loader_kwargs)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Sanity batch:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c7950-9cfc-4afb-b655-a2ea27262f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
